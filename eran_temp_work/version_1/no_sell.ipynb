{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "########################\n",
    "### Global variables ###\n",
    "########################\n",
    "\n",
    "HOURS_IN_A_WEEK = 168\n",
    "\n",
    "# Size of the agent's pool\n",
    "AGENT_WATER_VOLUME_MAX = 300\n",
    "# Price of missing a 1 water unit of consumer: \n",
    "# e.g agent's water volume = 10, consumer demand = 20, price = (20-10) * PENALTY_PER_WATER_UNIT\n",
    "PENALTY_PER_WATER_UNIT = 1000\n",
    "\n",
    "TOTAL_DAILY_DEMAND = 1000\n",
    "\n",
    "\n",
    "\n",
    "#########################\n",
    "### Price calculation ###\n",
    "#########################\n",
    "\n",
    "def hourly_demand_means():\n",
    "    # Hourly water demand according to: \n",
    "    hourly_demand = np.array([\n",
    "        2, 2, 2, 2, 3, 5, 10, 12, 10, 8, 6, 5, 5, 5, 5, 6, 7, 9, 10, 9, 6, 4, 3, 2\n",
    "    ])\n",
    "    # Normalize: Daily demand is 1000\n",
    "    hourly_demand = (hourly_demand / hourly_demand.sum()) * TOTAL_DAILY_DEMAND\n",
    "\n",
    "    # on day 7: less demand\n",
    "    hourly_demand = np.append(np.tile(hourly_demand,6), hourly_demand / 2)\n",
    "    return hourly_demand\n",
    "\n",
    "\n",
    "\n",
    "def sample_demand(hour, std=10):\n",
    "    # Sample from a normal distribution, ensure demand is non-negative\n",
    "    hourly_demand = hourly_demand_means()\n",
    "    mean_demand = hourly_demand[hour] # Mean demand follows a daily pattern, higher during the day (6 AM to 6 PM)\n",
    "    return max(0, np.random.normal(mean_demand, std)) # When std_dev is relatively low we will get lines that are very very close to the original function.\n",
    "\n",
    "\n",
    "def calculate_price(amount_to_buy: float, base_price: float) -> float:\n",
    "    return min(amount_to_buy * base_price + 0.005 * base_price * (amount_to_buy -1) ** 2, PENALTY_PER_WATER_UNIT)\n",
    "\n",
    "\n",
    "def get_water_prices():\n",
    "    # expensive hours: 8:00-16:00\n",
    "    source_1_price = np.ones(24)\n",
    "    source_1_price[8:16] = 2\n",
    "    source_1_price = np.tile(source_1_price,7)\n",
    "    return source_1_price\n",
    "\n",
    "\n",
    "##############################################\n",
    "### Environment Definition : WaterSupplyEnv ###\n",
    "##############################################\n",
    "\n",
    "class WaterSupplyEnv(gym.Env):\n",
    "\n",
    "    def __init__(self, max_weeks=10):\n",
    "        super().__init__()\n",
    "        # State: [water_level, price_A, price_B, demand, current_hour]\n",
    "        self.max_weeks = max_weeks\n",
    "        self.observation_space = spaces.Box(low=0, high=np.inf, shape=(5,), dtype=np.float32)\n",
    "\n",
    "        # Actions: [buy_from_A, buy_from_B]\n",
    "        self.action_space = spaces.Box(low=0, high=AGENT_WATER_VOLUME_MAX, shape=(2,), dtype=np.float32)\n",
    "\n",
    "        # Environment parameters\n",
    "        self.max_water_level = AGENT_WATER_VOLUME_MAX\n",
    "        self.source_A_base_prices = get_water_prices()\n",
    "        \n",
    "        # Source B is more expensive\n",
    "        self.source_B_base_prices = 1.5 * self.source_A_base_prices\n",
    "\n",
    "    def _get_obs(self):\n",
    "        return np.array([self.water_level,\n",
    "                         self.price_A,\n",
    "                         self.price_B,\n",
    "                         self.demand,\n",
    "                         self.current_hour])\n",
    "    def _get_info(self):\n",
    "        # return more expicit info, should be used only for debugging\n",
    "        return {\"water_level\": self.water_level,\n",
    "                \"price_A\": self.price_A,\n",
    "                \"price_B\": self.price_B,\n",
    "                \"demand\": self.demand,\n",
    "                \"current_hour\": self.current_hour}\n",
    "\n",
    "    def reset(self, seed = None, options = None):\n",
    "        # seed self.np_random\n",
    "        super().reset(seed=seed)\n",
    "\n",
    "        # initialize env state\n",
    "        self.total_hours = 0\n",
    "        self.current_hour = 0\n",
    "        self.water_level = self.max_water_level # Initial water level\n",
    "        self.demand = sample_demand(self.current_hour) # Initial demand\n",
    "        self.price_A = self.source_A_base_prices[self.current_hour]\n",
    "        self.price_B = self.source_B_base_prices[self.current_hour]\n",
    "        self.total_reward = 0\n",
    "        return self._get_obs(), self._get_info() # obs, info\n",
    "\n",
    "    def step(self, action):\n",
    "        buy_from_A, buy_from_B = action\n",
    "\n",
    "        # Calculate penalty for unmet demand\n",
    "        unmet_demand_penalty = max(0, (self.demand - self.water_level) * PENALTY_PER_WATER_UNIT)\n",
    "        self.water_level = max(0, self.water_level - self.demand)\n",
    "\n",
    "        \n",
    "        # Costs and revenues\n",
    "        cost_A = calculate_price(buy_from_A, self.source_A_base_prices[self.current_hour])\n",
    "        cost_B = calculate_price(buy_from_B, self.source_B_base_prices[self.current_hour])\n",
    "        # Update water stock\n",
    "        self.water_level += buy_from_A + buy_from_B\n",
    "\n",
    "        # Calculate reward\n",
    "        reward = (- cost_A - cost_B) - unmet_demand_penalty # reward function\n",
    "        self.total_reward += reward\n",
    "\n",
    "        # Ensure constraints\n",
    "        self.water_level = min(self.max_water_level, self.water_level)  # Ensure water level does not surpass maximum\n",
    "\n",
    "        # Update state\n",
    "        self.total_hours += 1\n",
    "        self.current_hour = (self.current_hour + 1) % 168\n",
    "        self.demand = sample_demand(self.current_hour)\n",
    "        self.price_A = self.source_A_base_prices[self.current_hour]\n",
    "        self.price_B = self.source_B_base_prices[self.current_hour]\n",
    "\n",
    "        observation = self._get_obs()\n",
    "\n",
    "        # terminated = False  # TODO: Define terminal conditions if necessary\n",
    "        terminated = True if (self.max_weeks and self.total_hours >= 168 * self.max_weeks) else False\n",
    "        truncated = False # TODO: Define truncated conditions if necessary\n",
    "        info = self._get_info()\n",
    "        return observation, reward, terminated, truncated, info\n",
    "    \n",
    "    def seed(self, seed=None):\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    def render(self, mode=\"human\", **kwargs):\n",
    "        if kwargs.get(\"close\", False):\n",
    "            # If 'close' is passed, do nothing\n",
    "            return\n",
    "        print(f\"Current_Hour: {self.current_hour}, Water Stock: {self.water_level}, Price A: {self.price_A}, Price B: {self.price_B}, Demand: {self.demand}, MONEY: {self.total_reward}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Demo env use\n",
    "# env = WaterSupplyEnv(max_weeks=10)\n",
    "# env.reset()\n",
    "# i = 0\n",
    "# for _ in range(999999):\n",
    "#     i += 1\n",
    "#     print(\"Step: \", i)\n",
    "#     # action = env.action_space.sample()\n",
    "#     action = [10, 10]\n",
    "#     print(\"Chosen action: \", action)\n",
    "#     observation, reward, terminated, truncated, info = env.step(action)\n",
    "#     print(\"Render: \")\n",
    "#     env.render()\n",
    "#     if terminated:\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Discretisize Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscreteActions(gym.ActionWrapper):\n",
    "    # size_of_purchase: the resolution of water that can be bought: 10 => can by in \n",
    "    # units of 10, 20, 30 ...\n",
    "    def __init__(self, env, max_water_volume, size_of_purchase):\n",
    "        super().__init__(env)\n",
    "        # how many discrete actions per source (sqrt of the size of the discrete action space)\n",
    "        self.action_amount = max_water_volume // size_of_purchase + 1\n",
    "        # DQN need dicrete action space (not multidiscrete)\n",
    "        self.action_space = spaces.Discrete(self.action_amount * self.action_amount)\n",
    "    \n",
    "    def action_to_quantity(self, action):\n",
    "            from_source_1 = action // self.action_amount\n",
    "            from_source_2 = action % self.action_amount\n",
    "            return [from_source_1, from_source_2]\n",
    "\n",
    "    def action(self, action):\n",
    "        # action is of discrete space with size: action_amount * action_amount\n",
    "        from_source_1, from_source_2 = self.action_to_quantity(action)\n",
    "        return [from_source_1, from_source_2]\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscreteObservation(gym.ObservationWrapper):\n",
    "    def __init__(self, env, water_level_resolution, price_resolution, demand_resolution, time_resolution):\n",
    "        super().__init__(env)\n",
    "        # time_resolution: the number of hours in a time frame, max is 168 (A full week -> only 1 time frame)      \n",
    "\n",
    "        self.water_level_resolution = water_level_resolution\n",
    "        self.price_resolution = price_resolution\n",
    "        self.demand_resolution = demand_resolution\n",
    "        self.time_resolution = time_resolution\n",
    "\n",
    "        self.amount_of_water = AGENT_WATER_VOLUME_MAX // water_level_resolution\n",
    "        self.amount_of_price = PENALTY_PER_WATER_UNIT // price_resolution\n",
    "        self.amount_of_demand = TOTAL_DAILY_DEMAND // demand_resolution\n",
    "        self.amount_of_time = HOURS_IN_A_WEEK // time_resolution\n",
    "        self.observation_space = spaces.Discrete(self.amount_of_water * self.amount_of_price * self.amount_of_price * self.amount_of_demand * self.amount_of_time)\n",
    "        \n",
    "    def observation(self, observation):\n",
    "        # observation: [water_level, price_A, price_B, demand, current_hour]\n",
    "        water_level, price_A, price_B, demand, current_hour = observation\n",
    "\n",
    "        water_idx = int(water_level // self.water_level_resolution)\n",
    "        price_A_idx = int(price_A // self.price_resolution)\n",
    "        price_B_idx = int(price_B // self.price_resolution)\n",
    "        demand_idx = int(demand // self.demand_resolution)\n",
    "        time_idx = int(current_hour // self.time_resolution)\n",
    "        \n",
    "        # Flatten into a single discrete index\n",
    "        # index = w_idx + (W) * [ p_idx + (P) * ( d_idx + (D) * t_idx ) ]\n",
    "        discrete_obs = (\n",
    "            water_idx\n",
    "            + self.amount_of_water * (\n",
    "                price_A_idx\n",
    "                + self.amount_of_price * (\n",
    "                    price_B_idx\n",
    "                        + self.amount_of_price * (\n",
    "                        demand_idx\n",
    "                        + self.amount_of_demand * time_idx\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        return discrete_obs\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified action space: Discrete(49)\n"
     ]
    }
   ],
   "source": [
    "# Create the environment\n",
    "env = WaterSupplyEnv(max_weeks=1)\n",
    "\n",
    "# Wrap the environment to discretize the actions & observations\n",
    "env = DiscreteActions(env, size_of_purchase=50, max_water_volume=300)\n",
    "env = DiscreteObservation(env, water_level_resolution=50, price_resolution=100, demand_resolution=100, time_resolution=168)\n",
    "\n",
    "\n",
    "# Now, env.action_space is Discrete, so DQN will work\n",
    "print(\"Modified action space:\", env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,\n",
       " {'water_level': 300,\n",
       "  'price_A': 1.0,\n",
       "  'price_B': 1.5,\n",
       "  'demand': 31.66623006444722,\n",
       "  'current_hour': 0})"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demo\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example\n",
    "# 30 + 30 * ( 1 + 1000 * ( 1 + 1000 * (20 + 168 * 0)))\n",
    "\n",
    "# (600030060,\n",
    "#  {'water_level': 300,\n",
    "#   'price_A': 1.0,\n",
    "#   'price_B': 1.5,\n",
    "#   'demand': 20.36692872444756,\n",
    "#   'current_hour': 0})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stable Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[155], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mDQN\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMlpPolicy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0001\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mlearn(total_timesteps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000000\u001b[39m, log_interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdqn_water1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\eranw\\miniconda3\\envs\\DEEP\\Lib\\site-packages\\stable_baselines3\\dqn\\dqn.py:141\u001b[0m, in \u001b[0;36mDQN.__init__\u001b[1;34m(self, policy, env, learning_rate, buffer_size, learning_starts, batch_size, tau, gamma, train_freq, gradient_steps, replay_buffer_class, replay_buffer_kwargs, optimize_memory_usage, target_update_interval, exploration_fraction, exploration_initial_eps, exploration_final_eps, max_grad_norm, stats_window_size, tensorboard_log, policy_kwargs, verbose, seed, device, _init_setup_model)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexploration_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _init_setup_model:\n\u001b[1;32m--> 141\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\eranw\\miniconda3\\envs\\DEEP\\Lib\\site-packages\\stable_baselines3\\dqn\\dqn.py:144\u001b[0m, in \u001b[0;36mDQN._setup_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_setup_model\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_aliases()\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;66;03m# Copy running stats, see GH issue #996\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eranw\\miniconda3\\envs\\DEEP\\Lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:205\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm._setup_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplay_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplay_buffer_class(\n\u001b[0;32m    190\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer_size,\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mreplay_buffer_kwargs,\n\u001b[0;32m    197\u001b[0m     )\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_class(\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space,\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space,\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_schedule,\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_kwargs,\n\u001b[0;32m    204\u001b[0m )\n\u001b[1;32m--> 205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;66;03m# Convert train freq parameter to TrainFreq object\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_train_freq()\n",
      "File \u001b[1;32mc:\\Users\\eranw\\miniconda3\\envs\\DEEP\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1174\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1171\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1172\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m-> 1174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\eranw\\miniconda3\\envs\\DEEP\\Lib\\site-packages\\torch\\nn\\modules\\module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eranw\\miniconda3\\envs\\DEEP\\Lib\\site-packages\\torch\\nn\\modules\\module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eranw\\miniconda3\\envs\\DEEP\\Lib\\site-packages\\torch\\nn\\modules\\module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eranw\\miniconda3\\envs\\DEEP\\Lib\\site-packages\\torch\\nn\\modules\\module.py:805\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 805\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    806\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    808\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eranw\\miniconda3\\envs\\DEEP\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1160\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1154\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1155\u001b[0m             device,\n\u001b[0;32m   1156\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1157\u001b[0m             non_blocking,\n\u001b[0;32m   1158\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[0;32m   1159\u001b[0m         )\n\u001b[1;32m-> 1160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1164\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "model = DQN(\"MlpPolicy\", env, verbose=1, learning_rate=0.0001)\n",
    "model.learn(total_timesteps=10000, log_interval=10)\n",
    "model.save(\"dqn_water1\")\n",
    "del model # remove to demonstrate saving and loading\n",
    "model = DQN.load(\"dqn_water1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: -1.505\n",
      "Current_Hour: 1, Water Stock: 292.3497066473418, Price A: 1.0, Price B: 1.5, Demand: 13.078710682155263, MONEY: -1.505\n",
      "Reward: -1.505\n",
      "Current_Hour: 2, Water Stock: 280.27099596518656, Price A: 1.0, Price B: 1.5, Demand: 22.030938360870014, MONEY: -3.01\n",
      "Reward: -1.505\n",
      "Current_Hour: 3, Water Stock: 259.2400576043165, Price A: 1.0, Price B: 1.5, Demand: 29.590783180614512, MONEY: -4.515\n",
      "Reward: -207.9475\n",
      "Current_Hour: 4, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 12.582604793912486, MONEY: -212.46249999999998\n",
      "Reward: -1.505\n",
      "Current_Hour: 5, Water Stock: 288.4173952060875, Price A: 1.0, Price B: 1.5, Demand: 33.279249629052316, MONEY: -213.96749999999997\n",
      "Reward: -207.9475\n",
      "Current_Hour: 6, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 78.86382821057026, MONEY: -421.91499999999996\n",
      "Reward: -207.9475\n",
      "Current_Hour: 7, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 75.17531734686524, MONEY: -629.8625\n",
      "Reward: -207.9475\n",
      "Current_Hour: 8, Water Stock: 300, Price A: 2.0, Price B: 3.0, Demand: 71.33362268205346, MONEY: -837.81\n",
      "Reward: -415.895\n",
      "Current_Hour: 9, Water Stock: 300, Price A: 2.0, Price B: 3.0, Demand: 57.08284281878672, MONEY: -1253.705\n",
      "Reward: -415.895\n",
      "Current_Hour: 10, Water Stock: 300, Price A: 2.0, Price B: 3.0, Demand: 56.73708830365153, MONEY: -1669.6\n",
      "Reward: -415.895\n",
      "Current_Hour: 11, Water Stock: 300, Price A: 2.0, Price B: 3.0, Demand: 45.006179206577556, MONEY: -2085.495\n",
      "Reward: -415.895\n",
      "Current_Hour: 12, Water Stock: 300, Price A: 2.0, Price B: 3.0, Demand: 34.25870722957826, MONEY: -2501.39\n",
      "Reward: -53.375\n",
      "Current_Hour: 13, Water Stock: 288.74129277042175, Price A: 2.0, Price B: 3.0, Demand: 38.37792438226381, MONEY: -2554.765\n",
      "Reward: -415.895\n",
      "Current_Hour: 14, Water Stock: 300, Price A: 2.0, Price B: 3.0, Demand: 38.787303460754245, MONEY: -2970.66\n",
      "Reward: -415.895\n",
      "Current_Hour: 15, Water Stock: 300, Price A: 2.0, Price B: 3.0, Demand: 47.91382766986002, MONEY: -3386.555\n",
      "Reward: -415.895\n",
      "Current_Hour: 16, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 56.591645342856026, MONEY: -3802.45\n",
      "Reward: -207.9475\n",
      "Current_Hour: 17, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 69.10183092223934, MONEY: -4010.3975\n",
      "Reward: -207.9475\n",
      "Current_Hour: 18, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 71.6417581739539, MONEY: -4218.345\n",
      "Reward: -207.9475\n",
      "Current_Hour: 19, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 43.5485370181337, MONEY: -4426.2925000000005\n",
      "Reward: -207.9475\n",
      "Current_Hour: 20, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 53.015694678429014, MONEY: -4634.240000000001\n",
      "Reward: -207.9475\n",
      "Current_Hour: 21, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 37.210782092083335, MONEY: -4842.187500000001\n",
      "Reward: -207.9475\n",
      "Current_Hour: 22, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 27.954822521924786, MONEY: -5050.135000000001\n",
      "Reward: -26.6875\n",
      "Current_Hour: 23, Water Stock: 295.04517747807523, Price A: 1.0, Price B: 1.5, Demand: 2.7589438204182013, MONEY: -5076.822500000001\n",
      "Reward: -1.505\n",
      "Current_Hour: 24, Water Stock: 293.286233657657, Price A: 1.0, Price B: 1.5, Demand: 22.826519284234443, MONEY: -5078.327500000001\n",
      "Reward: -1.505\n",
      "Current_Hour: 25, Water Stock: 271.45971437342257, Price A: 1.0, Price B: 1.5, Demand: 0.8933821298224363, MONEY: -5079.832500000001\n",
      "Reward: -1.505\n",
      "Current_Hour: 26, Water Stock: 271.56633224360013, Price A: 1.0, Price B: 1.5, Demand: 13.148764480801294, MONEY: -5081.3375000000015\n",
      "Reward: -1.505\n",
      "Current_Hour: 27, Water Stock: 259.41756776279885, Price A: 1.0, Price B: 1.5, Demand: 17.073100597855436, MONEY: -5082.842500000002\n",
      "Reward: -1.505\n",
      "Current_Hour: 28, Water Stock: 243.3444671649434, Price A: 1.0, Price B: 1.5, Demand: 6.254174376611946, MONEY: -5084.347500000002\n",
      "Reward: -1.505\n",
      "Current_Hour: 29, Water Stock: 238.09029278833145, Price A: 1.0, Price B: 1.5, Demand: 46.773736214665846, MONEY: -5085.852500000002\n",
      "Reward: -207.9475\n",
      "Current_Hour: 30, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 95.13924546195156, MONEY: -5293.800000000002\n",
      "Reward: -207.9475\n",
      "Current_Hour: 31, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 80.4938223747186, MONEY: -5501.747500000002\n",
      "Reward: -207.9475\n",
      "Current_Hour: 32, Water Stock: 300, Price A: 2.0, Price B: 3.0, Demand: 82.23281820886162, MONEY: -5709.695000000002\n",
      "Reward: -415.895\n",
      "Current_Hour: 33, Water Stock: 300, Price A: 2.0, Price B: 3.0, Demand: 63.42910556877273, MONEY: -6125.590000000002\n",
      "Reward: -415.895\n",
      "Current_Hour: 34, Water Stock: 300, Price A: 2.0, Price B: 3.0, Demand: 32.193474338342334, MONEY: -6541.485000000002\n",
      "Reward: -53.375\n",
      "Current_Hour: 35, Water Stock: 290.80652566165764, Price A: 2.0, Price B: 3.0, Demand: 38.248482993866965, MONEY: -6594.860000000002\n",
      "Reward: -415.895\n",
      "Current_Hour: 36, Water Stock: 300, Price A: 2.0, Price B: 3.0, Demand: 42.54563811901619, MONEY: -7010.755000000003\n",
      "Reward: -415.895\n",
      "Current_Hour: 37, Water Stock: 300, Price A: 2.0, Price B: 3.0, Demand: 35.472538592274574, MONEY: -7426.650000000003\n",
      "Reward: -53.375\n",
      "Current_Hour: 38, Water Stock: 287.5274614077254, Price A: 2.0, Price B: 3.0, Demand: 19.981026939260254, MONEY: -7480.025000000003\n",
      "Reward: -3.01\n",
      "Current_Hour: 39, Water Stock: 268.5464344684652, Price A: 2.0, Price B: 3.0, Demand: 41.65275481568546, MONEY: -7483.0350000000035\n",
      "Reward: -415.895\n",
      "Current_Hour: 40, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 53.80186776285301, MONEY: -7898.930000000004\n",
      "Reward: -207.9475\n",
      "Current_Hour: 41, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 85.09899746103491, MONEY: -8106.877500000004\n",
      "Reward: -207.9475\n",
      "Current_Hour: 42, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 70.16206628239182, MONEY: -8314.825000000004\n",
      "Reward: -207.9475\n",
      "Current_Hour: 43, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 78.9221171342968, MONEY: -8522.772500000005\n",
      "Reward: -207.9475\n",
      "Current_Hour: 44, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 42.250581210173166, MONEY: -8730.720000000005\n",
      "Reward: -207.9475\n",
      "Current_Hour: 45, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 30.612021043161647, MONEY: -8938.667500000005\n",
      "Reward: -26.6875\n",
      "Current_Hour: 46, Water Stock: 292.38797895683837, Price A: 1.0, Price B: 1.5, Demand: 19.61193897539323, MONEY: -8965.355000000005\n",
      "Reward: -1.505\n",
      "Current_Hour: 47, Water Stock: 273.77603998144514, Price A: 1.0, Price B: 1.5, Demand: 9.522400725824927, MONEY: -8966.860000000004\n",
      "Reward: -1.505\n",
      "Current_Hour: 48, Water Stock: 265.2536392556202, Price A: 1.0, Price B: 1.5, Demand: 4.666088563133487, MONEY: -8968.365000000003\n",
      "Reward: -1.505\n",
      "Current_Hour: 49, Water Stock: 261.58755069248673, Price A: 1.0, Price B: 1.5, Demand: 9.094305569657926, MONEY: -8969.870000000003\n",
      "Reward: -1.505\n",
      "Current_Hour: 50, Water Stock: 253.4932451228288, Price A: 1.0, Price B: 1.5, Demand: 30.85308250493662, MONEY: -8971.375000000002\n",
      "Reward: -26.6875\n",
      "Current_Hour: 51, Water Stock: 245.64016261789217, Price A: 1.0, Price B: 1.5, Demand: 21.219771540389104, MONEY: -8998.062500000002\n",
      "Reward: -1.505\n",
      "Current_Hour: 52, Water Stock: 225.42039107750307, Price A: 1.0, Price B: 1.5, Demand: 29.796069992272827, MONEY: -8999.567500000001\n",
      "Reward: -207.9475\n",
      "Current_Hour: 53, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 32.970749614930995, MONEY: -9207.515000000001\n",
      "Reward: -26.6875\n",
      "Current_Hour: 54, Water Stock: 290.029250385069, Price A: 1.0, Price B: 1.5, Demand: 59.454143964521975, MONEY: -9234.202500000001\n",
      "Reward: -207.9475\n",
      "Current_Hour: 55, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 70.15215606202608, MONEY: -9442.150000000001\n",
      "Reward: -207.9475\n",
      "Current_Hour: 56, Water Stock: 300, Price A: 2.0, Price B: 3.0, Demand: 66.11920654153288, MONEY: -9650.097500000002\n",
      "Reward: -415.895\n",
      "Current_Hour: 57, Water Stock: 300, Price A: 2.0, Price B: 3.0, Demand: 62.460656487427464, MONEY: -10065.992500000002\n",
      "Reward: -415.895\n",
      "Current_Hour: 58, Water Stock: 300, Price A: 2.0, Price B: 3.0, Demand: 45.67050705897128, MONEY: -10481.887500000003\n",
      "Reward: -415.895\n",
      "Current_Hour: 59, Water Stock: 300, Price A: 2.0, Price B: 3.0, Demand: 29.267217107001436, MONEY: -10897.782500000003\n",
      "Reward: -3.01\n",
      "Current_Hour: 60, Water Stock: 271.73278289299856, Price A: 2.0, Price B: 3.0, Demand: 46.25055630307202, MONEY: -10900.792500000003\n",
      "Reward: -415.895\n",
      "Current_Hour: 61, Water Stock: 300, Price A: 2.0, Price B: 3.0, Demand: 42.48719606247727, MONEY: -11316.687500000004\n",
      "Reward: -415.895\n",
      "Current_Hour: 62, Water Stock: 300, Price A: 2.0, Price B: 3.0, Demand: 25.817994367818233, MONEY: -11732.582500000004\n",
      "Reward: -3.01\n",
      "Current_Hour: 63, Water Stock: 275.18200563218176, Price A: 2.0, Price B: 3.0, Demand: 48.53459345320236, MONEY: -11735.592500000004\n",
      "Reward: -415.895\n",
      "Current_Hour: 64, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 34.3957486319938, MONEY: -12151.487500000005\n",
      "Reward: -26.6875\n",
      "Current_Hour: 65, Water Stock: 288.6042513680062, Price A: 1.0, Price B: 1.5, Demand: 59.41753177921217, MONEY: -12178.175000000005\n",
      "Reward: -207.9475\n",
      "Current_Hour: 66, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 67.28222332523762, MONEY: -12386.122500000005\n",
      "Reward: -207.9475\n",
      "Current_Hour: 67, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 68.54595340270609, MONEY: -12594.070000000005\n",
      "Reward: -207.9475\n",
      "Current_Hour: 68, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 42.31137309561999, MONEY: -12802.017500000005\n",
      "Reward: -207.9475\n",
      "Current_Hour: 69, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 12.583769362616763, MONEY: -13009.965000000006\n",
      "Reward: -1.505\n",
      "Current_Hour: 70, Water Stock: 288.41623063738325, Price A: 1.0, Price B: 1.5, Demand: 23.711019895809628, MONEY: -13011.470000000005\n",
      "Reward: -1.505\n",
      "Current_Hour: 71, Water Stock: 265.70521074157364, Price A: 1.0, Price B: 1.5, Demand: 5.850910359383656, MONEY: -13012.975000000004\n",
      "Reward: -1.505\n",
      "Current_Hour: 72, Water Stock: 260.85430038219, Price A: 1.0, Price B: 1.5, Demand: 9.58000854241739, MONEY: -13014.480000000003\n",
      "Reward: -1.505\n",
      "Current_Hour: 73, Water Stock: 252.2742918397726, Price A: 1.0, Price B: 1.5, Demand: 14.844041213392984, MONEY: -13015.985000000002\n",
      "Reward: -1.505\n",
      "Current_Hour: 74, Water Stock: 238.4302506263796, Price A: 1.0, Price B: 1.5, Demand: 17.537193024090584, MONEY: -13017.490000000002\n",
      "Reward: -1.505\n",
      "Current_Hour: 75, Water Stock: 221.89305760228902, Price A: 1.0, Price B: 1.5, Demand: 24.671105791670005, MONEY: -13018.995\n",
      "Reward: -26.6875\n",
      "Current_Hour: 76, Water Stock: 220.221951810619, Price A: 1.0, Price B: 1.5, Demand: 35.7070722405475, MONEY: -13045.6825\n",
      "Reward: -207.9475\n",
      "Current_Hour: 77, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 38.35909327022142, MONEY: -13253.630000000001\n",
      "Reward: -207.9475\n",
      "Current_Hour: 78, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 61.83059528683346, MONEY: -13461.577500000001\n",
      "Reward: -207.9475\n",
      "Current_Hour: 79, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 79.17032577523136, MONEY: -13669.525000000001\n",
      "Reward: -207.9475\n",
      "Current_Hour: 80, Water Stock: 300, Price A: 2.0, Price B: 3.0, Demand: 70.77992223864683, MONEY: -13877.472500000002\n",
      "Reward: -415.895\n",
      "Current_Hour: 81, Water Stock: 300, Price A: 2.0, Price B: 3.0, Demand: 66.51264289304986, MONEY: -14293.367500000002\n",
      "Reward: -415.895\n",
      "Current_Hour: 82, Water Stock: 300, Price A: 2.0, Price B: 3.0, Demand: 42.5178102877829, MONEY: -14709.262500000003\n",
      "Reward: -415.895\n",
      "Current_Hour: 83, Water Stock: 300, Price A: 2.0, Price B: 3.0, Demand: 44.985554477082474, MONEY: -15125.157500000003\n",
      "Reward: -415.895\n",
      "Current_Hour: 84, Water Stock: 300, Price A: 2.0, Price B: 3.0, Demand: 45.292695416984365, MONEY: -15541.052500000003\n",
      "Reward: -415.895\n",
      "Current_Hour: 85, Water Stock: 300, Price A: 2.0, Price B: 3.0, Demand: 32.325547410986026, MONEY: -15956.947500000004\n",
      "Reward: -53.375\n",
      "Current_Hour: 86, Water Stock: 290.674452589014, Price A: 2.0, Price B: 3.0, Demand: 50.80805658773965, MONEY: -16010.322500000004\n",
      "Reward: -415.895\n",
      "Current_Hour: 87, Water Stock: 300, Price A: 2.0, Price B: 3.0, Demand: 39.55656209765942, MONEY: -16426.217500000002\n",
      "Reward: -53.375\n",
      "Current_Hour: 88, Water Stock: 283.4434379023406, Price A: 1.0, Price B: 1.5, Demand: 59.62176282379585, MONEY: -16479.592500000002\n",
      "Reward: -207.9475\n",
      "Current_Hour: 89, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 68.09151869638522, MONEY: -16687.54\n",
      "Reward: -207.9475\n",
      "Current_Hour: 90, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 74.34736137246323, MONEY: -16895.4875\n",
      "Reward: -207.9475\n",
      "Current_Hour: 91, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 66.16317148977458, MONEY: -17103.434999999998\n",
      "Reward: -207.9475\n",
      "Current_Hour: 92, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 33.952057992271065, MONEY: -17311.382499999996\n",
      "Reward: -26.6875\n",
      "Current_Hour: 93, Water Stock: 289.0479420077289, Price A: 1.0, Price B: 1.5, Demand: 12.789670277712872, MONEY: -17338.069999999996\n",
      "Reward: -1.505\n",
      "Current_Hour: 94, Water Stock: 277.2582717300161, Price A: 1.0, Price B: 1.5, Demand: 32.70794002223789, MONEY: -17339.574999999997\n",
      "Reward: -26.6875\n",
      "Current_Hour: 95, Water Stock: 267.5503317077782, Price A: 1.0, Price B: 1.5, Demand: 3.2549916042966895, MONEY: -17366.262499999997\n",
      "Reward: -1.505\n",
      "Current_Hour: 96, Water Stock: 265.2953401034815, Price A: 1.0, Price B: 1.5, Demand: 9.319244051039101, MONEY: -17367.767499999998\n",
      "Reward: -1.505\n",
      "Current_Hour: 97, Water Stock: 256.9760960524424, Price A: 1.0, Price B: 1.5, Demand: 12.742007764924814, MONEY: -17369.2725\n",
      "Reward: -1.505\n",
      "Current_Hour: 98, Water Stock: 245.2340882875176, Price A: 1.0, Price B: 1.5, Demand: 0, MONEY: -17370.7775\n",
      "Reward: -1.505\n",
      "Current_Hour: 99, Water Stock: 246.2340882875176, Price A: 1.0, Price B: 1.5, Demand: 1.4581497997323964, MONEY: -17372.2825\n",
      "Reward: -1.505\n",
      "Current_Hour: 100, Water Stock: 245.7759384877852, Price A: 1.0, Price B: 1.5, Demand: 20.819516577273305, MONEY: -17373.787500000002\n",
      "Reward: -26.6875\n",
      "Current_Hour: 101, Water Stock: 247.9564219105119, Price A: 1.0, Price B: 1.5, Demand: 58.76118892807253, MONEY: -17400.475000000002\n",
      "Reward: -207.9475\n",
      "Current_Hour: 102, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 76.06889430254665, MONEY: -17608.4225\n",
      "Reward: -207.9475\n",
      "Current_Hour: 103, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 77.06220827908673, MONEY: -17816.37\n",
      "Reward: -207.9475\n",
      "Current_Hour: 104, Water Stock: 300, Price A: 2.0, Price B: 3.0, Demand: 85.88847277083528, MONEY: -18024.317499999997\n",
      "Reward: -415.895\n",
      "Current_Hour: 105, Water Stock: 300, Price A: 2.0, Price B: 3.0, Demand: 66.65756420108964, MONEY: -18440.212499999998\n",
      "Reward: -415.895\n",
      "Current_Hour: 106, Water Stock: 300, Price A: 2.0, Price B: 3.0, Demand: 46.37874117327716, MONEY: -18856.1075\n",
      "Reward: -415.895\n",
      "Current_Hour: 107, Water Stock: 300, Price A: 2.0, Price B: 3.0, Demand: 31.20456465836706, MONEY: -19272.0025\n",
      "Reward: -53.375\n",
      "Current_Hour: 108, Water Stock: 291.7954353416329, Price A: 2.0, Price B: 3.0, Demand: 18.055750251783103, MONEY: -19325.3775\n",
      "Reward: -3.01\n",
      "Current_Hour: 109, Water Stock: 274.73968508984984, Price A: 2.0, Price B: 3.0, Demand: 31.58974266264589, MONEY: -19328.387499999997\n",
      "Reward: -53.375\n",
      "Current_Hour: 110, Water Stock: 266.14994242720394, Price A: 2.0, Price B: 3.0, Demand: 34.98566156478346, MONEY: -19381.762499999997\n",
      "Reward: -53.375\n",
      "Current_Hour: 111, Water Stock: 254.16428086242047, Price A: 2.0, Price B: 3.0, Demand: 55.12625215600213, MONEY: -19435.137499999997\n",
      "Reward: -415.895\n",
      "Current_Hour: 112, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 57.922163559585826, MONEY: -19851.032499999998\n",
      "Reward: -207.9475\n",
      "Current_Hour: 113, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 55.9722986323346, MONEY: -20058.979999999996\n",
      "Reward: -207.9475\n",
      "Current_Hour: 114, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 71.00144307748869, MONEY: -20266.927499999994\n",
      "Reward: -207.9475\n",
      "Current_Hour: 115, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 62.8929886405169, MONEY: -20474.874999999993\n",
      "Reward: -207.9475\n",
      "Current_Hour: 116, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 39.824215733173986, MONEY: -20682.82249999999\n",
      "Reward: -21.8125\n",
      "Current_Hour: 117, Water Stock: 280.175784266826, Price A: 1.0, Price B: 1.5, Demand: 29.90774919854599, MONEY: -20704.63499999999\n",
      "Reward: -26.6875\n",
      "Current_Hour: 118, Water Stock: 273.26803506828, Price A: 1.0, Price B: 1.5, Demand: 14.928267088779961, MONEY: -20731.32249999999\n",
      "Reward: -1.505\n",
      "Current_Hour: 119, Water Stock: 259.33976797950004, Price A: 1.0, Price B: 1.5, Demand: 0.9410286481633143, MONEY: -20732.827499999992\n",
      "Reward: -1.505\n",
      "Current_Hour: 120, Water Stock: 259.39873933133674, Price A: 1.0, Price B: 1.5, Demand: 19.047918616689294, MONEY: -20734.332499999993\n",
      "Reward: -26.6875\n",
      "Current_Hour: 121, Water Stock: 263.35082071464745, Price A: 1.0, Price B: 1.5, Demand: 8.302445013850997, MONEY: -20761.019999999993\n",
      "Reward: -1.505\n",
      "Current_Hour: 122, Water Stock: 256.04837570079644, Price A: 1.0, Price B: 1.5, Demand: 24.581104558514348, MONEY: -20762.524999999994\n",
      "Reward: -26.6875\n",
      "Current_Hour: 123, Water Stock: 254.4672711422821, Price A: 1.0, Price B: 1.5, Demand: 20.39208729193698, MONEY: -20789.212499999994\n",
      "Reward: -26.6875\n",
      "Current_Hour: 124, Water Stock: 257.0751838503451, Price A: 1.0, Price B: 1.5, Demand: 27.43462343222363, MONEY: -20815.899999999994\n",
      "Reward: -26.6875\n",
      "Current_Hour: 125, Water Stock: 252.64056041812148, Price A: 1.0, Price B: 1.5, Demand: 45.03556531373184, MONEY: -20842.587499999994\n",
      "Reward: -207.9475\n",
      "Current_Hour: 126, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 67.20539259764415, MONEY: -21050.534999999993\n",
      "Reward: -207.9475\n",
      "Current_Hour: 127, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 87.61294973206418, MONEY: -21258.48249999999\n",
      "Reward: -207.9475\n",
      "Current_Hour: 128, Water Stock: 300, Price A: 2.0, Price B: 3.0, Demand: 80.29821361956618, MONEY: -21466.42999999999\n",
      "Reward: -415.895\n",
      "Current_Hour: 129, Water Stock: 300, Price A: 2.0, Price B: 3.0, Demand: 48.913970777280305, MONEY: -21882.32499999999\n",
      "Reward: -415.895\n",
      "Current_Hour: 130, Water Stock: 300, Price A: 2.0, Price B: 3.0, Demand: 48.95359470556728, MONEY: -22298.21999999999\n",
      "Reward: -415.895\n",
      "Current_Hour: 131, Water Stock: 300, Price A: 2.0, Price B: 3.0, Demand: 15.630305455086074, MONEY: -22714.11499999999\n",
      "Reward: -3.01\n",
      "Current_Hour: 132, Water Stock: 285.36969454491395, Price A: 2.0, Price B: 3.0, Demand: 45.702796027804254, MONEY: -22717.12499999999\n",
      "Reward: -415.895\n",
      "Current_Hour: 133, Water Stock: 300, Price A: 2.0, Price B: 3.0, Demand: 31.84279820674874, MONEY: -23133.01999999999\n",
      "Reward: -53.375\n",
      "Current_Hour: 134, Water Stock: 291.15720179325126, Price A: 2.0, Price B: 3.0, Demand: 22.09213861532728, MONEY: -23186.39499999999\n",
      "Reward: -53.375\n",
      "Current_Hour: 135, Water Stock: 292.065063177924, Price A: 2.0, Price B: 3.0, Demand: 39.17965670245067, MONEY: -23239.76999999999\n",
      "Reward: -43.625\n",
      "Current_Hour: 136, Water Stock: 272.88540647547336, Price A: 1.0, Price B: 1.5, Demand: 42.43508692221534, MONEY: -23283.39499999999\n",
      "Reward: -207.9475\n",
      "Current_Hour: 137, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 70.14379736763864, MONEY: -23491.342499999988\n",
      "Reward: -207.9475\n",
      "Current_Hour: 138, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 68.43419057714779, MONEY: -23699.289999999986\n",
      "Reward: -207.9475\n",
      "Current_Hour: 139, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 55.98037931283818, MONEY: -23907.237499999985\n",
      "Reward: -207.9475\n",
      "Current_Hour: 140, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 52.17417892114411, MONEY: -24115.184999999983\n",
      "Reward: -207.9475\n",
      "Current_Hour: 141, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 49.43122694921401, MONEY: -24323.13249999998\n",
      "Reward: -207.9475\n",
      "Current_Hour: 142, Water Stock: 300, Price A: 1.0, Price B: 1.5, Demand: 7.135697778143573, MONEY: -24531.07999999998\n",
      "Reward: -1.505\n",
      "Current_Hour: 143, Water Stock: 293.8643022218564, Price A: 1.0, Price B: 1.5, Demand: 20.013556048179016, MONEY: -24532.58499999998\n",
      "Reward: -26.6875\n",
      "Current_Hour: 144, Water Stock: 296.8507461736774, Price A: 1.0, Price B: 1.5, Demand: 7.402452438449065, MONEY: -24559.27249999998\n",
      "Reward: -1.505\n",
      "Current_Hour: 145, Water Stock: 290.44829373522833, Price A: 1.0, Price B: 1.5, Demand: 2.1037451147121002, MONEY: -24560.777499999982\n",
      "Reward: -1.505\n",
      "Current_Hour: 146, Water Stock: 289.3445486205162, Price A: 1.0, Price B: 1.5, Demand: 16.997657032692498, MONEY: -24562.282499999983\n",
      "Reward: -26.6875\n",
      "Current_Hour: 147, Water Stock: 295.34689158782373, Price A: 1.0, Price B: 1.5, Demand: 0, MONEY: -24588.969999999983\n",
      "Reward: -1.505\n",
      "Current_Hour: 148, Water Stock: 296.34689158782373, Price A: 1.0, Price B: 1.5, Demand: 13.916459470024165, MONEY: -24590.474999999984\n",
      "Reward: -1.505\n",
      "Current_Hour: 149, Water Stock: 283.43043211779957, Price A: 1.0, Price B: 1.5, Demand: 25.66026100259707, MONEY: -24591.979999999985\n",
      "Reward: -26.6875\n",
      "Current_Hour: 150, Water Stock: 280.7701711152025, Price A: 1.0, Price B: 1.5, Demand: 39.871220810683894, MONEY: -24618.667499999985\n",
      "Reward: -21.8125\n",
      "Current_Hour: 151, Water Stock: 260.8989503045186, Price A: 1.0, Price B: 1.5, Demand: 58.54087709267749, MONEY: -24640.479999999985\n",
      "Reward: -207.9475\n",
      "Current_Hour: 152, Water Stock: 300, Price A: 2.0, Price B: 3.0, Demand: 50.35519657337541, MONEY: -24848.427499999983\n",
      "Reward: -415.895\n",
      "Current_Hour: 153, Water Stock: 300, Price A: 2.0, Price B: 3.0, Demand: 26.019081425009194, MONEY: -25264.322499999984\n",
      "Reward: -53.375\n",
      "Current_Hour: 154, Water Stock: 296.9809185749908, Price A: 2.0, Price B: 3.0, Demand: 22.132556716029804, MONEY: -25317.697499999984\n",
      "Reward: -53.375\n",
      "Current_Hour: 155, Water Stock: 297.848361858961, Price A: 2.0, Price B: 3.0, Demand: 28.926780629021028, MONEY: -25371.072499999984\n",
      "Reward: -53.375\n",
      "Current_Hour: 156, Water Stock: 291.92158122994, Price A: 2.0, Price B: 3.0, Demand: 28.758180648022865, MONEY: -25424.447499999984\n",
      "Reward: -53.375\n",
      "Current_Hour: 157, Water Stock: 286.16340058191713, Price A: 2.0, Price B: 3.0, Demand: 17.22013826321053, MONEY: -25477.822499999984\n",
      "Reward: -53.375\n",
      "Current_Hour: 158, Water Stock: 291.9432623187066, Price A: 2.0, Price B: 3.0, Demand: 29.908237575716946, MONEY: -25531.197499999984\n",
      "Reward: -53.375\n",
      "Current_Hour: 159, Water Stock: 285.03502474298966, Price A: 2.0, Price B: 3.0, Demand: 19.557398230059917, MONEY: -25584.572499999984\n",
      "Reward: -53.375\n",
      "Current_Hour: 160, Water Stock: 288.47762651292976, Price A: 1.0, Price B: 1.5, Demand: 27.22528689932519, MONEY: -25637.947499999984\n",
      "Reward: -26.6875\n",
      "Current_Hour: 161, Water Stock: 284.2523396136046, Price A: 1.0, Price B: 1.5, Demand: 26.6102169594339, MONEY: -25664.634999999984\n",
      "Reward: -26.6875\n",
      "Current_Hour: 162, Water Stock: 280.6421226541707, Price A: 1.0, Price B: 1.5, Demand: 21.09155602780656, MONEY: -25691.322499999984\n",
      "Reward: -26.6875\n",
      "Current_Hour: 163, Water Stock: 282.5505666263641, Price A: 1.0, Price B: 1.5, Demand: 10.965370849702616, MONEY: -25718.009999999984\n",
      "Reward: -26.6875\n",
      "Current_Hour: 164, Water Stock: 294.5851957766615, Price A: 1.0, Price B: 1.5, Demand: 20.823305248626113, MONEY: -25744.697499999984\n",
      "Reward: -26.6875\n",
      "Current_Hour: 165, Water Stock: 296.7618905280354, Price A: 1.0, Price B: 1.5, Demand: 23.71812616155993, MONEY: -25771.384999999984\n",
      "Reward: -26.6875\n",
      "Current_Hour: 166, Water Stock: 296.04376436647544, Price A: 1.0, Price B: 1.5, Demand: 0, MONEY: -25798.072499999984\n",
      "Reward: -1.505\n",
      "Current_Hour: 167, Water Stock: 297.04376436647544, Price A: 1.0, Price B: 1.5, Demand: 29.954276636419532, MONEY: -25799.577499999985\n",
      "Reward: -26.6875\n",
      "Current_Hour: 0, Water Stock: 290.0894877300559, Price A: 1.0, Price B: 1.5, Demand: 0.5642300525142581, MONEY: -25826.264999999985\n"
     ]
    }
   ],
   "source": [
    "obs, info = env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    print(\"Reward:\", reward)\n",
    "    env.render()\n",
    "    if terminated or truncated:\n",
    "        break\n",
    "        obs, info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DEEP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
