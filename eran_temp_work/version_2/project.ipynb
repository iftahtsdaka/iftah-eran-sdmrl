{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "# -----------------------\n",
    "# general\n",
    "# -----------------------\n",
    "import os\n",
    "# -----------------------\n",
    "# Gymnasium\n",
    "# -----------------------\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "from gymnasium.utils import seeding\n",
    "\n",
    "# -----------------------\n",
    "# Stable Baselines 3\n",
    "# -----------------------\n",
    "\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Global Constants\n",
    "# -----------------------\n",
    "TOTAL_DAILY_DEMAND = 1000\n",
    "PENALTY_PER_WATER_UNIT = 1000\n",
    "AGENT_WATER_VOLUME_MAX = 300\n",
    "HOURS_IN_A_WEEK = 168\n",
    "PRICE_A = 1 # base price A\n",
    "PREMIUM_FACTOR = 2 # how much a price get pricer on expensive hours\n",
    "PRICE_A_PREMIUM = PREMIUM_FACTOR * PRICE_A # price A on expensive hours\n",
    "PRICE_B_FACTOR = 1.5 # how much base price B is pricier than price A\n",
    "PRICE_B = PRICE_B_FACTOR * PRICE_A # base price B\n",
    "PRICE_B_PREMIUM = PREMIUM_FACTOR * PRICE_B # price B on expensive hours\n",
    "# -----------------------\n",
    "# Helper Functions\n",
    "# -----------------------\n",
    "def discretize(value, bucket_size):\n",
    "    \"\"\"Rounds the value to the nearest multiple of bucket_size.\"\"\"\n",
    "    return int(round(value / bucket_size)) * bucket_size\n",
    "\n",
    "def default_price_function(amount_to_buy, base_price):\n",
    "    return min(amount_to_buy * base_price + 0.005 * base_price * (amount_to_buy - 1) ** 2,\n",
    "               PENALTY_PER_WATER_UNIT)\n",
    "\n",
    "def get_hourly_demand_pattern():\n",
    "    \"\"\"\n",
    "    Returns 168 array of demands first 6 days sums to TOTAL_DAILY_DEMAND demand. \n",
    "    The last day sums to TOTAL_DAILY_DEMAND / 2 \n",
    "    \"\"\"\n",
    "    hourly_demand = np.array([2, 2, 2, 2, 3, 5, 10, 12, 10, 8, 6, 5, 5, 5, 5, 6, 7, 9, 10, 9, 6, 4, 3, 2])\n",
    "    hourly_demand = (hourly_demand / hourly_demand.sum()) * TOTAL_DAILY_DEMAND\n",
    "    # For a week: 6 full days and 1 day at half demand\n",
    "    hourly_demand = np.append(np.tile(hourly_demand, 6), hourly_demand / 2)\n",
    "    return hourly_demand\n",
    "\n",
    "def sample_demand(hour, std=10):\n",
    "    \"\"\" Sample[hour]: base hourly demand + normal noise \"\"\"\n",
    "    pattern = get_hourly_demand_pattern()\n",
    "    mean_demand = pattern[hour]\n",
    "    return max(0, np.random.normal(mean_demand, std))\n",
    "\n",
    "\n",
    "def get_water_prices(hours):\n",
    "    \"\"\"\n",
    "    Hourly prices over a day, 8am-4pm more expensive\n",
    "    \"\"\"\n",
    "    base_prices = np.ones(24) * PRICE_A\n",
    "    base_prices[8:16] = PRICE_A_PREMIUM  # More expensive between 8:00 and 16:00\n",
    "    base_prices = np.tile(base_prices, 7)[:hours]\n",
    "    return base_prices\n",
    "\n",
    "# -----------------------\n",
    "# Simplified Environment\n",
    "# -----------------------\n",
    "class SimplifiedWaterSupplyEnv(gym.Env):\n",
    "    def __init__(self,\n",
    "                 max_cycles=10,\n",
    "                 hours_per_cycle=HOURS_IN_A_WEEK,\n",
    "                 time_bucket_count=HOURS_IN_A_WEEK,\n",
    "                 water_bucket_count=AGENT_WATER_VOLUME_MAX,\n",
    "                 discrete_observations = False,\n",
    "                 discrete_actions = False,\n",
    "                 normalize_observations=False,\n",
    "                 normalize_actions=False,\n",
    "                 price_function=default_price_function):\n",
    "        \"\"\"\n",
    "        max_cycles: number of cycles (e.g. weeks)\n",
    "        hours_per_cycle: number of hours in one cycle (e.g. 168)\n",
    "        time_bucket_count: discrete time steps per cycle (aggregated from hours)\n",
    "        water_bucket_count: number of discrete water/demand levels\n",
    "        price_function: function for computing water cost\n",
    "\n",
    "        Note: Simplifying by using buckets is only relevant for discrete,\n",
    "        as continus has infinite number of options in any case!\n",
    "        \"\"\"\n",
    "        super(SimplifiedWaterSupplyEnv, self).__init__()\n",
    "        self.max_cycles = max_cycles # Finite horizon\n",
    "        self.hours_per_cycle = hours_per_cycle\n",
    "        self.time_bucket_count = time_bucket_count\n",
    "        self.discrete_observations = discrete_observations\n",
    "        self.discrete_actions = discrete_actions\n",
    "        self.price_function = price_function\n",
    "\n",
    "        # Time Interval size: How many original hours per bucket? \n",
    "        self.aggregation_interval = hours_per_cycle / time_bucket_count\n",
    "\n",
    "        # Determine the bucket size for water/demand.\n",
    "        self.water_bucket_count = water_bucket_count\n",
    "        self.water_bucket_size = AGENT_WATER_VOLUME_MAX / water_bucket_count\n",
    "\n",
    "    \n",
    "        # Observation: [water_level, price_A, price_B, demand, current_time_bucket]\n",
    "\n",
    "        # - water_level: [0,300] float\n",
    "        # - price_A: [1,2] float\n",
    "        # - price_B: [1.5,3] float\n",
    "        # - demand: [0,inf) float\n",
    "        # - current_time_bucket: [0, time_bucket_count]\n",
    "\n",
    "        low_bounds = np.array([\n",
    "            0,    # water_level min\n",
    "            PRICE_A,    # price_A min\n",
    "            PRICE_B,  # price_B min\n",
    "            0,    # demand min\n",
    "            0     # current_time_bucket min\n",
    "        ], dtype=np.float32)\n",
    "\n",
    "        high_bounds = np.array([\n",
    "            AGENT_WATER_VOLUME_MAX,                # water_level max\n",
    "            PRICE_A_PREMIUM,                  # price_A max\n",
    "            PRICE_B_PREMIUM,                  # price_B max\n",
    "            AGENT_WATER_VOLUME_MAX,             # demand max (assumed)\n",
    "            self.time_bucket_count  # current_time_bucket max\n",
    "        ], dtype=np.float32)\n",
    "\n",
    "        self.observation_space = spaces.Box(low=low_bounds, high=high_bounds, dtype=np.float32)\n",
    "\n",
    "        # Action: how much water to buy from each source (continuous; later wrapped to discrete)\n",
    "        self.action_space = spaces.Box(low=0, high=AGENT_WATER_VOLUME_MAX, shape=(2,), dtype=np.float32)\n",
    "\n",
    "        # Pre-compute hourly prices and then aggregate them into time buckets.\n",
    "        self.base_hourly_prices = get_water_prices(hours_per_cycle)\n",
    "        # Price B is more expensive than Price A\n",
    "        # self.source_A_base_prices = self._aggregate_prices(self.base_hourly_prices) # Simplify the Env\n",
    "        self.source_A_base_prices =self.base_hourly_prices[::int(self.aggregation_interval)]\n",
    "        self.source_B_base_prices = 1.5 * self.source_A_base_prices\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def _aggregate_prices(self, hourly_prices):\n",
    "        \"\"\"Aggregate (by Averaging) hourly prices into time buckets.\"\"\"\n",
    "        aggregated = []\n",
    "        for i in range(self.time_bucket_count):\n",
    "            start = int(i * self.aggregation_interval)\n",
    "            end = int((i + 1) * self.aggregation_interval)\n",
    "            agg_price = np.mean(hourly_prices[start:end])\n",
    "            aggregated.append(agg_price)\n",
    "        return np.array(aggregated)\n",
    "\n",
    "    def _aggregate_demand(self, start_hour):\n",
    "        \"\"\"Aggregate (by Averaging) demand over the time bucket and discretize it.\"\"\"\n",
    "        demands = [sample_demand(\n",
    "            h % self.hours_per_cycle\n",
    "            ) \n",
    "            for h in range(\n",
    "                start_hour, \n",
    "                start_hour + \n",
    "                int(self.aggregation_interval)\n",
    "                )]\n",
    "        avg_demand = np.mean(demands)\n",
    "        return avg_demand\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.current_cycle = 0\n",
    "        self.current_time_bucket = 0\n",
    "        self.np_random, _ = seeding.np_random(seed)\n",
    "\n",
    "        # Start with full water (discretized)\n",
    "        self.water_level = AGENT_WATER_VOLUME_MAX\n",
    "        if self.discrete_observations:\n",
    "            self.water_level = discretize(self.water_level, self.water_bucket_size)\n",
    "        self.total_reward = 0.0\n",
    "\n",
    "        # Initialize demand and prices for the first time bucket\n",
    "        self.demand = self._aggregate_demand(0)\n",
    "        self.price_A = self.source_A_base_prices[self.current_time_bucket]\n",
    "        self.price_B = self.source_B_base_prices[self.current_time_bucket]\n",
    "        return self._get_obs(), self._get_info()\n",
    "    \n",
    "    def get_raw_demands(self):\n",
    "       return [self._aggregate_demand(i) for i in range(self.time_bucket_count)]\n",
    "\n",
    "        \n",
    "    def step(self, action):\n",
    "        buy_from_A, buy_from_B = action\n",
    "\n",
    "        # Calculate penalty for unmet demand\n",
    "        unmet_demand = max(0, self.demand - self.water_level)\n",
    "        unmet_demand_penalty = unmet_demand * PENALTY_PER_WATER_UNIT\n",
    "\n",
    "        # Subtract demand (and discretize afterward)\n",
    "        self.water_level = max(0, self.water_level - self.demand)\n",
    "\n",
    "        # Compute cost using the pricing function\n",
    "        cost_A = self.price_function(buy_from_A, self.price_A)\n",
    "        cost_B = self.price_function(buy_from_B, self.price_B)\n",
    "\n",
    "        # Add purchased water and re-discretize\n",
    "        self.water_level += (buy_from_A + buy_from_B)\n",
    "        self.water_level = min(self.water_level, AGENT_WATER_VOLUME_MAX)\n",
    "        if self.discrete_observations:\n",
    "            self.water_level = discretize(self.water_level, self.water_bucket_size)\n",
    "\n",
    "        reward = - cost_A - cost_B - unmet_demand_penalty\n",
    "        self.total_reward += reward\n",
    "\n",
    "        # Advance the time bucket\n",
    "        self.current_time_bucket += 1\n",
    "        if self.current_time_bucket >= self.time_bucket_count:\n",
    "            self.current_cycle += 1\n",
    "            self.current_time_bucket = 0\n",
    "\n",
    "        done = self.current_cycle >= self.max_cycles\n",
    "\n",
    "        if not done:\n",
    "            start_hour = self.current_time_bucket * int(self.aggregation_interval)\n",
    "            self.demand = self._aggregate_demand(start_hour)\n",
    "            if self.discrete_observations:\n",
    "                self.demand = discretize(self.demand, self.water_bucket_size)\n",
    "            self.price_A = self.source_A_base_prices[self.current_time_bucket]\n",
    "            self.price_B = self.source_B_base_prices[self.current_time_bucket]\n",
    "\n",
    "        return self._get_obs(), reward, done, False, self._get_info()\n",
    "\n",
    "    def _get_obs(self):\n",
    "        return np.array([self.water_level, self.price_A, self.price_B, self.demand, self.current_time_bucket], dtype=np.float32)\n",
    "    \n",
    "    def get_obs(self):\n",
    "        return self._get_obs()\n",
    "\n",
    "    def _get_info(self):\n",
    "        return {\n",
    "            \"water_level\": self.water_level,\n",
    "            \"price_A\": self.price_A,\n",
    "            \"price_B\": self.price_B,\n",
    "            \"demand\": self.demand,\n",
    "            \"current_time_bucket\": self.current_time_bucket,\n",
    "            \"current_cycle\": self.current_cycle,\n",
    "            \"total_reward\": self.total_reward\n",
    "        }\n",
    "    \n",
    "    def set_state(self, state):\n",
    "        self.state=state\n",
    "        self.water_level, self.price_A, self.price_B, self.demand, self.current_time_bucket = state\n",
    "\n",
    "\n",
    "    def render(self):\n",
    "        info = self._get_info()\n",
    "        print(info)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete Wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Discrete Wrappers\n",
    "# -----------------------\n",
    "class DiscreteActions(gym.ActionWrapper):\n",
    "    \"\"\"\n",
    "    Wraps a continuous action space into a discrete one.\n",
    "    The agent can buy water in increments of size_of_purchase.\n",
    "    \"\"\"\n",
    "    def __init__(self, env, max_water_volume=AGENT_WATER_VOLUME_MAX, size_of_purchase=10):\n",
    "        super().__init__(env)\n",
    "        self.action_amount = max_water_volume // size_of_purchase\n",
    "        self.size_of_purchase = size_of_purchase\n",
    "        # Flattened action space: two sources => action_amount^2 possible actions.\n",
    "        self.action_space = spaces.Discrete(self.action_amount * self.action_amount)\n",
    "\n",
    "    def action_to_quantity(self, action):\n",
    "        from_source_1 = action // self.action_amount\n",
    "        from_source_2 = action % self.action_amount\n",
    "        return [from_source_1 * self.size_of_purchase, from_source_2 * self.size_of_purchase]\n",
    "\n",
    "    def action(self, action):\n",
    "        return self.action_to_quantity(action)\n",
    "\n",
    "class DiscreteObservation(gym.ObservationWrapper):\n",
    "    \"\"\"\n",
    "    Wraps the observation space into a single discrete index.\n",
    "    Each component is discretized according to the provided resolutions.\n",
    "    \"\"\"\n",
    "    def __init__(self, env, time_buckets, water_buckets):\n",
    "        super().__init__(env)\n",
    "        self.water_buckets = water_buckets\n",
    "        # Assumer demand is always less than AGENT_WATER_VOLUME_MAX \n",
    "        self.water_resolution = (AGENT_WATER_VOLUME_MAX+1) / (water_buckets) # how much water each discrete \"water volume interval\" holds\n",
    "        # self.time_resolution = (HOURS_IN_A_WEEK) / time_buckets # how much hour each dicrete interval represents\n",
    "\n",
    "        # amount of intervals per feature\n",
    "        self.amount_of_water = water_buckets\n",
    "        self.amount_of_price = 2 # (price A: 1, 2.  Price B: 1.5, 3)\n",
    "        \n",
    "        self.amount_of_demand = water_buckets\n",
    "        self.amount_of_time = time_buckets\n",
    "\n",
    "        # The flattened observation index\n",
    "        self.observation_space = spaces.Discrete(self.amount_of_water * \n",
    "                                                 self.amount_of_price * \n",
    "                                                 self.amount_of_price * \n",
    "                                                 self.amount_of_demand * \n",
    "                                                 self.amount_of_time)\n",
    "\n",
    "    def get_discreteobservationwarpper_info(self):\n",
    "        return {\n",
    "            \"amount_of_water\": self.amount_of_water,\n",
    "            \"amount_of_price\": self.amount_of_price,\n",
    "            \"amount_of_demand\": self.amount_of_demand,\n",
    "            \"amount_of_time\": self.amount_of_time,\n",
    "        }\n",
    "    \n",
    "    def observation(self, observation):\n",
    "        # observation: [water_level, price_A, price_B, demand, current_time_bucket]\n",
    "        #               0-300        1,2      1.5 3    0-300   timebucket\n",
    "        water_level, price_A, price_B, demand, current_time_bucket = observation\n",
    "        \n",
    "        assert demand <= AGENT_WATER_VOLUME_MAX, f\"Assertion failed: demand={demand} exceeds AGENT_WATER_VOLUME_MAX ({AGENT_WATER_VOLUME_MAX})\"\n",
    "        water_idx = int(water_level // self.water_resolution)\n",
    "        price_A_idx = 0 if price_A == PRICE_A else 1\n",
    "        price_B_idx = 0 if price_B == PRICE_B else 1\n",
    "        demand_idx = int(demand // self.water_resolution)\n",
    "        time_idx = int(current_time_bucket) # DELETE: // self.time_resolution)\n",
    "        \n",
    "        discrete_obs = (\n",
    "            water_idx +\n",
    "            self.amount_of_water * (\n",
    "                price_A_idx +\n",
    "                self.amount_of_price * (\n",
    "                    price_B_idx +\n",
    "                    self.amount_of_price * (\n",
    "                        demand_idx +\n",
    "                        self.amount_of_demand * time_idx\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        return discrete_obs\n",
    "    \n",
    "\n",
    "class NormalizeObservationWrapper(gym.ObservationWrapper):\n",
    "    \"\"\"\n",
    "    Normalizes continuous observation features to [0,1]:\n",
    "        - water_level: [0,300]  -> normalized value = water_level / 300\n",
    "        - price_A: [1,2]       -> normalized value = (price_A - 1) / (2 - 1)\n",
    "        - price_B: [1.5,3]     -> normalized value = (price_B - 1.5) / (3 - 1.5)\n",
    "        - demand: [0, TOTAL_DAILY_DEMAND] -> normalized value = demand / TOTAL_DAILY_DEMAND\n",
    "        - current_time_bucket: [0, hours_per_cycle] -> normalized value = current_time_bucket / hours_per_cycle\n",
    "    \"\"\"\n",
    "    def __init__(self, env, hours_per_cycle, discrete_observations):\n",
    "        super().__init__(env)\n",
    "        self.hours_per_cycle = hours_per_cycle\n",
    "        self.discrete_observations = discrete_observations\n",
    "\n",
    "        if not discrete_observations:\n",
    "            self.observation_space = spaces.Box(low=0, high=1,\n",
    "                                            shape=env.observation_space.shape,\n",
    "                                            dtype=np.float32)\n",
    "\n",
    "    def observation(self, obs):\n",
    "        if self.discrete_observations:\n",
    "            return obs\n",
    "        \n",
    "        water_level, price_A, price_B, demand, current_time = obs\n",
    "        norm_water = water_level / AGENT_WATER_VOLUME_MAX\n",
    "        norm_price_A = (price_A - PRICE_A) / (PREMIUM_FACTOR * PRICE_A - PRICE_A)\n",
    "        norm_price_B = (price_B - PRICE_B) / (PREMIUM_FACTOR * PRICE_B - PRICE_B)\n",
    "        norm_demand = demand / AGENT_WATER_VOLUME_MAX\n",
    "        norm_time = current_time / self.hours_per_cycle\n",
    "        return np.array([norm_water, norm_price_A, norm_price_B, norm_demand, norm_time],\n",
    "                        dtype=np.float32)\n",
    "    \n",
    "\n",
    "class NormalizeActionWrapper(gym.ActionWrapper):\n",
    "    def __init__(self, env, discrete_actions):\n",
    "        super().__init__(env)\n",
    "        self.discrete_actions = discrete_actions\n",
    "\n",
    "        if not self.discrete_actions:\n",
    "            self.action_space= spaces.Box(low=0, high=1,\n",
    "                                            shape=env.action_space.shape,\n",
    "                                            dtype=np.float32)\n",
    "    def action(self, action):\n",
    "        buy_from_A, buy_from_B = action # ranges [0,1], [0,1] \n",
    "        # convert to env value range [0,300]\n",
    "        buy_from_A = AGENT_WATER_VOLUME_MAX * buy_from_A\n",
    "        buy_from_B = AGENT_WATER_VOLUME_MAX * buy_from_B\n",
    "        return [buy_from_A, buy_from_B]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_env(time_buckets=5, water_buckets=5, discrete_observations=True, discrete_actions=True, normalize=False):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_env(time_buckets=5, water_buckets=5, discrete_observations=True, discrete_actions=True, normalize=False):\n",
    "# -----------------------\n",
    "# Environment Creation Function\n",
    "# -----------------------\n",
    "def create_env(\n",
    "        time_buckets=HOURS_IN_A_WEEK, \n",
    "        water_buckets=AGENT_WATER_VOLUME_MAX, \n",
    "        discrete_observations=True, \n",
    "        discrete_actions=True, \n",
    "        normalize_observations=False,\n",
    "        normalize_actions=False,\n",
    "        ):\n",
    "    \"\"\"\n",
    "    time_buckets: number of discrete time steps per cycle (also hours_per_cycle).\n",
    "    water_buckets: number of discrete water levels (e.g., 5 levels).\n",
    "    \"\"\"\n",
    "    env = SimplifiedWaterSupplyEnv(\n",
    "        max_cycles=max_cycles,\n",
    "        hours_per_cycle=HOURS_IN_A_WEEK,       # How long is the original raw cycle (should remain 168)       \n",
    "        time_bucket_count=time_buckets,        # number of time steps equals time_buckets\n",
    "        water_bucket_count=water_buckets,   # water_bucket_count divisions yield water_buckets levels\n",
    "        discrete_observations=discrete_observations,\n",
    "        discrete_actions=discrete_actions,\n",
    "        normalize_observations=normalize_observations,\n",
    "        normalize_actions=normalize_actions,\n",
    "    )\n",
    "    # Determine the purchase increment unit\n",
    "    purchase_increment = AGENT_WATER_VOLUME_MAX // (water_buckets)\n",
    "    if discrete_actions:    \n",
    "        env = DiscreteActions(\n",
    "            env, \n",
    "        max_water_volume=AGENT_WATER_VOLUME_MAX, \n",
    "        size_of_purchase=purchase_increment\n",
    "        )\n",
    "    \n",
    "    if discrete_observations:\n",
    "        env = DiscreteObservation(\n",
    "        env,\n",
    "        time_buckets=time_buckets,  \n",
    "        water_buckets=water_buckets,   \n",
    "    )\n",
    "    \n",
    "    if normalize:\n",
    "        env = NormalizeObservationWrapper(\n",
    "            env,\n",
    "            hours_per_cycle=time_buckets,\n",
    "            discrete_observations=discrete_observations,\n",
    "        )\n",
    "\n",
    "        env = NormalizeActionWrapper(\n",
    "            env,\n",
    "            discrete_actions=discrete_actions,\n",
    "        )\n",
    "        \n",
    "    return env\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eranw\\miniconda3\\envs\\filo\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:78: UserWarning: The `render_mode` attribute is not defined in your environment. It will be set to None.\n",
      "  warnings.warn(\"The `render_mode` attribute is not defined in your environment. It will be set to None.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 25        |\n",
      "|    ep_rew_mean      | -1.61e+04 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 1235      |\n",
      "|    time_elapsed     | 0         |\n",
      "|    total_timesteps  | 100       |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 25        |\n",
      "|    ep_rew_mean      | -1.74e+04 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 1289      |\n",
      "|    time_elapsed     | 0         |\n",
      "|    total_timesteps  | 200       |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 25        |\n",
      "|    ep_rew_mean      | -1.77e+04 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 1343      |\n",
      "|    time_elapsed     | 0         |\n",
      "|    total_timesteps  | 300       |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 25        |\n",
      "|    ep_rew_mean      | -1.85e+04 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 1362      |\n",
      "|    time_elapsed     | 0         |\n",
      "|    total_timesteps  | 400       |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 25        |\n",
      "|    ep_rew_mean      | -1.85e+04 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 20        |\n",
      "|    fps              | 1375      |\n",
      "|    time_elapsed     | 0         |\n",
      "|    total_timesteps  | 500       |\n",
      "-----------------------------------\n",
      "Mean reward: -21947.84 +/- 0.00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a vectorized environment (n_envs=1 for simplicity)\n",
    "env = make_vec_env(lambda: create_env(time_buckets=5, water_buckets=5,discrete_observations=True, discrete_actions=True, normalize=False), n_envs=1)\n",
    "# Create and configure the DQN model\n",
    "model = DQN(\"MlpPolicy\", env, verbose=1, learning_rate=1e-3,\n",
    "            buffer_size=10, learning_starts=1000, exploration_fraction=0.1)\n",
    "\n",
    "# Train the model\n",
    "model.learn(total_timesteps=500)\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"dqn_water_supply\")\n",
    "\n",
    "# Evaluate the model over 10 episodes\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10)\n",
    "print(f\"Mean reward: {mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check environemnt\n",
    "Accordance with Gymnasium standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eranw\\miniconda3\\envs\\filo\\Lib\\site-packages\\stable_baselines3\\common\\env_checker.py:462: UserWarning: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) cf. https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\n",
      "  warnings.warn(\n",
      "c:\\Users\\eranw\\miniconda3\\envs\\filo\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:78: UserWarning: The `render_mode` attribute is not defined in your environment. It will be set to None.\n",
      "  warnings.warn(\"The `render_mode` attribute is not defined in your environment. It will be set to None.\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "# Define a set of expected keys from env.info()\n",
    "EXPECTED_INFO_KEYS = {\n",
    "    \"water_level\",\n",
    "    \"price_A\",\n",
    "    \"price_B\",\n",
    "    \"demand\",\n",
    "    \"current_time_bucket\",\n",
    "    \"current_cycle\",\n",
    "    \"total_reward\",\n",
    "}\n",
    "\n",
    "def test_reset_environment():\n",
    "    \"\"\"Test that the environment resets properly.\"\"\"\n",
    "    # Create environment with a couple of cycles for a quick test\n",
    "    env = SimplifiedWaterSupplyEnv(max_cycles=2,\n",
    "                                   time_bucket_count=168, water_bucket_count=300)\n",
    "    obs, info = env.reset()\n",
    "    \n",
    "    # Observation should be a numpy array with shape (5,)\n",
    "    assert isinstance(obs, np.ndarray), \"Observation is not a numpy array.\"\n",
    "    assert obs.shape == (5,), f\"Expected observation shape (5,), got {obs.shape}\"\n",
    "    \n",
    "    # Info should include all expected keys\n",
    "    for key in EXPECTED_INFO_KEYS:\n",
    "        assert key in info, f\"Missing key '{key}' in info dictionary.\"\n",
    "\n",
    "def test_step_environment():\n",
    "    \"\"\"Test a single step of the environment.\"\"\"\n",
    "    env = SimplifiedWaterSupplyEnv(max_cycles=2, hours_per_cycle=168,\n",
    "                                   time_bucket_count=168, water_bucket_count=300)\n",
    "    obs, info = env.reset()\n",
    "    \n",
    "    # Use a sample continuous action (example: buy 10 units from each source)\n",
    "    action = np.array([10.0, 10.0])\n",
    "    new_obs, reward, done, truncated, info = env.step(action)\n",
    "    \n",
    "    # Check observation shape and type\n",
    "    assert isinstance(new_obs, np.ndarray), \"New observation is not a numpy array.\"\n",
    "    assert new_obs.shape == (5,), f\"Expected new_obs shape (5,), got {new_obs.shape}\"\n",
    "    \n",
    "    # Check reward and termination flags\n",
    "    assert isinstance(reward, float), \"Reward is not a float.\"\n",
    "    assert isinstance(done, bool), \"Done flag is not boolean.\"\n",
    "    assert isinstance(truncated, bool), \"Truncated flag is not boolean.\"\n",
    "    \n",
    "    # Check info dictionary again\n",
    "    for key in EXPECTED_INFO_KEYS:\n",
    "        assert key in info, f\"Missing key '{key}' in info dictionary after step.\"\n",
    "\n",
    "def test_env_with_check_env():\n",
    "    \"\"\"Run gym's check_env to ensure the environment conforms to the Gym API.\"\"\"\n",
    "    env = SimplifiedWaterSupplyEnv()\n",
    "    # This will raise an error if the environment does not follow the Gym API.\n",
    "    check_env(env)\n",
    "\n",
    "def test_discrete_actions_wrapper():\n",
    "    \"\"\"Test the DiscreteActions wrapper functionality.\"\"\"\n",
    "    env = SimplifiedWaterSupplyEnv()\n",
    "    # Wrap the env to get discrete actions (e.g., actions in increments of 10)\n",
    "    wrapped_env = DiscreteActions(env, max_water_volume=300, size_of_purchase=10)\n",
    "    \n",
    "    # Check that the action_space is now Discrete\n",
    "    assert isinstance(wrapped_env.action_space, gym.spaces.Discrete), \\\n",
    "        \"Action space is not Discrete after wrapping.\"\n",
    "    \n",
    "    # Test conversion: for a given discrete action index, the wrapper should return a list with two values\n",
    "    discrete_index = 5  # example discrete action index\n",
    "    continuous_action = wrapped_env.action(discrete_index)\n",
    "    assert isinstance(continuous_action, list), \"Returned action is not a list.\"\n",
    "    assert len(continuous_action) == 2, \"Expected two actions (one per source).\"\n",
    "    \n",
    "    # Check that each action quantity is a multiple of the size_of_purchase (10)\n",
    "    for q in continuous_action:\n",
    "        assert q % 10 == 0, f\"Action {q} is not a multiple of 10.\"\n",
    "\n",
    "def test_discrete_observation_wrapper():\n",
    "    \"\"\"Test the DiscreteObservation wrapper functionality.\"\"\"\n",
    "    env = SimplifiedWaterSupplyEnv()\n",
    "    # Wrap the env so that observations are converted to a single discrete index.\n",
    "    wrapped_env = DiscreteObservation(env, water_buckets=10,\n",
    "                                      time_buckets=20)\n",
    "    \n",
    "    # Check that the observation_space is now Discrete\n",
    "    assert isinstance(wrapped_env.observation_space, gym.spaces.Discrete), \\\n",
    "        \"Observation space is not Discrete after wrapping.\"\n",
    "    \n",
    "    # Reset the base env and then transform the observation\n",
    "    obs, _ = env.reset()\n",
    "    discrete_obs = wrapped_env.observation(obs)\n",
    "    # For discrete wrappers, the observation is typically an integer index.\n",
    "    assert isinstance(discrete_obs, int), \"Discrete observation is not an integer.\"\n",
    "\n",
    "\n",
    "test_reset_environment()\n",
    "test_step_environment()\n",
    "test_env_with_check_env()\n",
    "test_discrete_actions_wrapper()\n",
    "test_discrete_observation_wrapper()\n",
    "print(\"All tests passed successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs: \n",
      "Discrete(512)\n",
      "act: \n",
      "Discrete(16)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[130], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mact: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtest_env\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m):\n\u001b[1;32m----> 9\u001b[0m     action, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(obs, deterministic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     10\u001b[0m     obs, reward, done, _, info \u001b[38;5;241m=\u001b[39m test_env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[0;32m     11\u001b[0m     test_env\u001b[38;5;241m.\u001b[39mrender()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Run a few test episodes to observe behavior\n",
    "test_env = create_env(water_buckets=4,time_buckets=8)\n",
    "obs, info = test_env.reset()\n",
    "\n",
    "print(f\"obs: \\n{test_env.observation_space}\")\n",
    "print(f\"act: \\n{test_env.action_space}\")\n",
    "\n",
    "for _ in range(20):\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, _, info = test_env.step(action)\n",
    "    test_env.render()\n",
    "    if done:\n",
    "        obs, info = test_env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tb = 4\n",
    "# wb = 5\n",
    "# test_env = create_env(\n",
    "\n",
    "# )\n",
    "# test_env.reset()\n",
    "# test_env.get_raw_demands()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = 8\n",
    "wb = 5\n",
    "\n",
    "env = make_vec_env(lambda: create_env(\n",
    "    time_buckets=tb,\n",
    "    water_buckets=wb, \n",
    "    discrete_actions=True, \n",
    "    discrete_observations=True,\n",
    "    ), n_envs=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs size: 800, expected: 800\n",
      "act size: 25, expected: 25\n",
      "--------------------------------------------------\n",
      "obs: \n",
      "Discrete(800)\n",
      "act: \n",
      "Discrete(25)\n"
     ]
    }
   ],
   "source": [
    "# water_resolution = AGENT_WATER_VOLUME_MAX // wb\n",
    "# demand_buckets = AGENT_WATER_VOLUME_MAX // water_resolution\n",
    "\n",
    "print(f\"obs size: {env.observation_space.n}, expected: {wb * 2 * 2 * wb * tb }\")\n",
    "print(f\"act size: {env.action_space.n}, expected: {wb * wb}\")\n",
    "print(f\"-\" * 50)\n",
    "print(f\"obs: \\n{env.observation_space}\")\n",
    "print(f\"act: \\n{env.action_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount_of_water: 5\n",
      "amount_of_price: 2\n",
      "amount_of_demand: 5\n",
      "amount_of_time: 8\n",
      "--------------------------------------------------\n",
      "obs: \n",
      "Discrete(800)\n",
      "act: \n",
      "Discrete(25)\n"
     ]
    }
   ],
   "source": [
    "discrete_actions=True\n",
    "discrete_observations=True\n",
    "normalize=False\n",
    "\n",
    "env_normalized = create_env(\n",
    "    time_buckets=tb,\n",
    "    water_buckets=wb, \n",
    "    discrete_actions=discrete_actions, \n",
    "    discrete_observations=discrete_observations,\n",
    "    normalize=normalize,\n",
    "    )\n",
    "\n",
    "if discrete_observations:\n",
    "    info = env_normalized.get_discreteobservationwarpper_info()\n",
    "    for (k,v) in info.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "\n",
    "# print(f\"obs size: {env_normalized.observation_space.n}, expected: {wb * 2 * 2 * wb * tb }\")\n",
    "# print(f\"act size: {env_normalized.action_space.n}, expected: {wb * wb}\")\n",
    "print(f\"-\" * 50)\n",
    "print(f\"obs: \\n{env_normalized.observation_space}\")\n",
    "print(f\"act: \\n{env_normalized.action_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Also normalize the actions\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[300.0, 1.0, 1.5, 3.071830565932615, 0]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from env_nosell import create_env\n",
    "env = create_env(discrete_actions=True, discrete_observations=True)\n",
    "obs = env.reset(seed=40)\n",
    "state=env.unwrapped.get_state()\n",
    "state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36299, {'water_level': 300.0, 'price_A': 1.0, 'price_B': 1.5, 'demand': 30.23916505486971, 'current_time_bucket': 0, 'current_cycle': 0, 'total_reward': 0.0})\n",
      "[300.0, 1.0, 1.5, 30.23916505486971, 0]\n",
      "{'water_level': 300.0, 'price_A': 1.0, 'price_B': 1.5, 'demand': 3.071830565932615, 'current_time_bucket': 0, 'current_cycle': 0, 'total_reward': 0.0}\n"
     ]
    }
   ],
   "source": [
    "print(env.reset(seed=30))\n",
    "print(env.unwrapped.get_state())\n",
    "env.unwrapped.set_state(state)\n",
    "env.unwrapped.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.unwrapped.get_state()\n",
    "env.unwrapped.set_state(state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
